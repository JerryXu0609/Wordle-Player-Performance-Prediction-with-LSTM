# 基于 LSTM 的 Wordle 玩家表现预测研究

本项目旨在利用深度学习方法，对 Wordle 游戏玩家的每日表现进行数据驱动的建模与预测。通过对 Wordle 官方公布的玩家统计数据进行时间序列分析，本研究构建了一个基于 **长短期记忆网络（LSTM）** 的预测模型，用于预测下一日玩家的平均猜词次数（mean_tries），并进一步探索 Wordle 难度变化背后的行为模式。

------

## **🎯 项目目标** 

本项目的核心目标是构建一个能够根据前 7 日玩家表现数据，**预测下一日玩家平均尝试次数** 的机器学习系统。该预测结果可以用来：

- 分析 Wordle 难度是否具有可预测性
- 研究玩家行为在时间维度上的演化规律
- 评估深度学习模型在行为类时间序列任务中的适用性
- 为游戏设计、玩家建模与认知行为研究提供数据支持

------

## **📊 研究数据来源** 

数据来自 Wordle 游戏中每日玩家的汇总统计信息，包括：

- 各尝试次数（1–6次）的占比
- 失败率 (X)
- 使用 hard mode 的玩家数量
- 总玩家数量
- 成功率
- 平均尝试次数（mean_tries）
- 日期、单词长度等辅助特征

经过清洗与处理后，数据被构建为适合序列模型使用的滑动窗口格式。

------

## **🧠 模型介绍**

本项目主模型为 **LSTM（Long Short-Term Memory）**，其特点包括：

- 能够捕捉序列数据的时间依赖特征
- 适合中小规模时间序列预测
- 在本项目提供的有限数据中表现稳健

模型输入：过去 7 天的玩家表现特征

模型输出：下一天的 mean_tries

为了扩展研究，本项目还实现了一个 **Transformer Encoder 模型**，用于对比不同序列模型在小样本环境下的表现差异。

---

## **📈 核心实验结果**

实验表明，LSTM 能稳定拟合 Wordle 玩家表现数据，但由于 Wordle 难度具有一定随机性，模型更倾向于预测总体趋势，而难以捕捉局部剧烈变化。

Transformer 模型则由于数据规模过小而无法学习有效的注意力结构，注意力权重呈均匀分布，验证了复杂模型在小样本时间序列中的局限性。

------

## **🛠 项目包含内容 **

- 原始数据清洗与结构化处理
- 时间序列滑动窗口构建
- LSTM 模型设计与训练
- 模型性能指标评估
- 预测曲线、Loss 曲线与残差分析
- Transformer 注意力可视化（扩展实验）
- 完整的论文内容与数据说明文档

------

## **📚 适用人群与研究价值** 

本项目适合：

- 深度学习与时间序列预测学习者
- 研究行为数据、认知计算或游戏分析的学生与研究人员
- 探索 LSTM / Transformer 在小样本序列任务中表现的开发者
- 参加数学建模、美赛（MCM）、科研项目的学习者

研究价值在于：

- 提供了一个干净可用的时间序列预测数据集
- 分析模型表现并提出针对小样本场景的深刻讨论
- 给出 LSTM 与 Transformer 在真实任务中的对比见解
- 形成完整、可扩展的研究流程

